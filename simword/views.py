import os
from django.shortcuts import get_object_or_404
from django.http import JsonResponse
from gensim.models import KeyedVectors
from .models import AnswerWord, BaseWord
from django.db import IntegrityError
import json
from django.conf import settings
import threading
import time
import random

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
VEC_FILE = os.path.join(settings.BASE_DIR, 'cc.ko.300.vec')
KV_FILE = os.path.join(settings.BASE_DIR, 'cc.ko.300.kv')

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜ (í•œ ë²ˆë§Œ ë¡œë“œ í›„ ê³„ì† ì‚¬ìš©)
model = None
_model_lock = threading.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½


class PowerfulMemoryKeeper:
    def __init__(self, model):
        self.model = model
        self.is_running = True
        self.access_count = 0
        self._lock = threading.Lock()

    def intensive_memory_access(self):
        """ë©”ëª¨ë¦¬ ì „ì²´ ì˜ì—­ì„ ì§€ì†ì ìœ¼ë¡œ í„°ì¹˜ (ìµœì í™”ë¨)"""
        while self.is_running:
            try:
                with self._lock:  # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
                    # 1. ë²¡í„° ë°°ì—´ ì „ì²´ë¥¼ ìµœì í™”ëœ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼
                    if hasattr(self.model, 'vectors') and self.model.vectors is not None:
                        total_vectors = len(self.model.vectors)
                        chunk_size = min(500, total_vectors // 20)  # ë” ì‘ì€ ì²­í¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

                        for i in range(0, total_vectors, chunk_size):
                            end_idx = min(i + chunk_size, total_vectors)

                            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹
                            for j in range(i, end_idx, 10):  # 10ê°œì”© ê±´ë„ˆë›°ë©° ìƒ˜í”Œë§
                                if j < total_vectors:
                                    _ = self.model.vectors[j].sum()  # ê°œë³„ ë²¡í„° í•©ê³„

                            time.sleep(0.005)  # 5msë¡œ ë‹¨ì¶•

                    # 2. í‚¤ ì¸ë±ìŠ¤ ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼
                    if hasattr(self.model, 'key_to_index'):
                        keys = list(self.model.key_to_index.keys())
                        sample_keys = random.sample(keys, min(50, len(keys)))  # 50ê°œë¡œ ì¤„ì„

                        for key in sample_keys:
                            _ = self.model.key_to_index[key]

                    # 3. ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ìˆ˜í–‰
                    self.perform_dummy_calculations()

                self.access_count += 1
                if self.access_count % 10 == 0:  # 10ë²ˆë§ˆë‹¤ í•œë²ˆì”©ë§Œ ì¶œë ¥
                    print(f"ë©”ëª¨ë¦¬ ìœ ì§€ ì‘ì—… #{self.access_count} ì™„ë£Œ")

            except Exception as e:
                print(f"ë©”ëª¨ë¦¬ ìœ ì§€ ì—ëŸ¬: {e}")

            # 12ì´ˆë§ˆë‹¤ ì‹¤í–‰ (ì¢€ ë” ìì£¼)
            time.sleep(12)

    def perform_dummy_calculations(self):
        """ì‹¤ì œ ëª¨ë¸ ì—°ì‚° ìˆ˜í–‰ìœ¼ë¡œ ê³„ì‚° ì—”ì§„ë„ í™œì„±í™”"""
        try:
            keys = list(self.model.key_to_index.keys())
            if len(keys) >= 4:  # 4ê°œ ë‹¨ì–´ë¡œ ë” ë‹¤ì–‘í•œ ì—°ì‚°
                sample_words = random.sample(keys, 4)

                # ë‹¤ì–‘í•œ ì—°ì‚° ìˆ˜í–‰
                _ = self.model.similarity(sample_words[0], sample_words[1])
                _ = self.model.similarity(sample_words[2], sample_words[3])

                # ë²¡í„° ì§ì ‘ ì ‘ê·¼
                for word in sample_words[:2]:
                    _ = self.model[word]

        except Exception as e:
            print(f"ë”ë¯¸ ê³„ì‚° ì—ëŸ¬: {e}")

    def start_background_keeper(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©”ëª¨ë¦¬ ìœ ì§€ ì‹œì‘"""
        keeper_thread = threading.Thread(target=self.intensive_memory_access, daemon=True)
        keeper_thread.start()
        print("ğŸš€ ê°•ë ¥í•œ ë©”ëª¨ë¦¬ í‚¤í¼ ì‹œì‘!")
        return keeper_thread

    def stop(self):
        """ë©”ëª¨ë¦¬ í‚¤í¼ ì¤‘ì§€"""
        self.is_running = False


# ì „ì—­ ë©”ëª¨ë¦¬ í‚¤í¼ ë³€ìˆ˜
memory_keeper = None


def load_model():
    """FastText ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥"""
    global model, memory_keeper

    with _model_lock:  # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        if model is not None:  # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ì¤‘ë³µ ë°©ì§€
            return

        if os.path.exists(KV_FILE):
            print("ê¸°ì¡´ KV íŒŒì¼ ë¡œë“œ ì¤‘...")
            model = KeyedVectors.load(KV_FILE)
        else:
            print("ì›ë³¸ ë²¡í„° íŒŒì¼ ë¡œë“œ ë° ë³€í™˜ ì¤‘...")
            # ì›ë³¸ ë²¡í„° íŒŒì¼ ë¡œë“œ
            model = KeyedVectors.load_word2vec_format(VEC_FILE, binary=False, unicode_errors="ignore")

            # ë²¡í„°ë¥¼ float16ìœ¼ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
            model.vectors = model.vectors.astype("float16")

            # ë³€í™˜ëœ ëª¨ë¸ì„ ì €ì¥
            model.save(KV_FILE)
            print("KV íŒŒì¼ ì €ì¥ ì™„ë£Œ")

        # ğŸš€ PowerfulMemoryKeeperë§Œ ì‚¬ìš© (keep_model_warm_improved ì œê±°)
        memory_keeper = PowerfulMemoryKeeper(model)
        memory_keeper.start_background_keeper()

        print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì–´íœ˜ í¬ê¸°: {len(model.key_to_index):,}ê°œ")


# ğŸš€ ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ í•œ ë²ˆ ë¡œë“œ
load_model()


def answer_word_count(request):
    """ì „ì²´ AnswerWord ê°œìˆ˜ë¥¼ ë°˜í™˜"""
    total_count = AnswerWord.objects.all().count()
    return JsonResponse({"total_count": total_count})


def get_similarity_rank_list(request, id):
    """íŠ¹ì • AnswerWordì™€ BaseWord ê°„ ìœ ì‚¬ë„ ë­í‚¹ ìƒìœ„ 100ê°œë¥¼ ë°˜í™˜"""
    try:
        answer = get_object_or_404(AnswerWord, pk=id)
        candidate_words = list(BaseWord.objects.values_list("base_word", flat=True))

        if not candidate_words:
            return JsonResponse({"error": "No candidate words found in the database."}, status=404)

        if answer.answer_word not in model.key_to_index:
            return JsonResponse({"error": f"Answer word '{answer.answer_word}' not found in the model."}, status=400)

        similarities = [
            {
                "word": word,
                "similarity_percentage": round(float(model.similarity(answer.answer_word, word)) * 100, 2)
            }
            for word in candidate_words
            if word in model.key_to_index and word != answer.answer_word
        ]

        if not similarities:
            return JsonResponse({"error": "No valid candidate words found for similarity calculation."}, status=404)

        similarities = sorted(similarities, key=lambda x: x["similarity_percentage"], reverse=True)

        top_similarities = [
            {"word": item["word"], "similarity_percentage": item["similarity_percentage"], "rank": rank + 1}
            for rank, item in enumerate(similarities[:100])
        ]

        return JsonResponse({
            "id": id,
            "answer_word": answer.answer_word,
            "top_100_similarities": top_similarities
        })
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)


def calculate_similarity(request, id, input_word):
    """ì…ë ¥ ë‹¨ì–´ì™€ ì •ë‹µ ë‹¨ì–´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³ , ë­í‚¹ì„ ë°˜í™˜"""
    try:
        answer = get_object_or_404(AnswerWord, pk=id)

        response = get_similarity_rank_list(request, id)
        if response.status_code != 200:
            return response

        data = json.loads(response.content)
        similarities = data.get("top_100_similarities", [])

        base_word_exists = BaseWord.objects.filter(base_word=input_word).exists()

        rank = "?"
        for item in similarities:
            if item["word"] == input_word:
                rank = item["rank"] if item["rank"] <= 100 else "ìˆœìœ„ ë°–"
                break

        if rank == "?" and base_word_exists:
            rank = "ìˆœìœ„ ë°–"

        if input_word not in model.key_to_index:
            return JsonResponse({"error": f"Input word '{input_word}' not found in the model."}, status=400)
        if answer.answer_word not in model.key_to_index:
            return JsonResponse({"error": f"Answer word '{answer.answer_word}' not found in the model."}, status=400)

        similarity_score = model.similarity(input_word, answer.answer_word)
        similarity_percentage = round(similarity_score * 100, 2)

        if similarity_percentage == 100:
            rank = "ì •ë‹µ!"

        if not base_word_exists:
            try:
                new_base_word = BaseWord(base_word=input_word)
                new_base_word.save()
            except IntegrityError:
                pass

        return JsonResponse({
            "id": id,
            "input_word": input_word,
            "similarity_percentage": similarity_percentage,
            "rank": rank
        })
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)


# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_memory_keeper_status(request):
    """ë©”ëª¨ë¦¬ í‚¤í¼ ìƒíƒœ í™•ì¸"""
    global memory_keeper
    if memory_keeper:
        return JsonResponse({
            "status": "running" if memory_keeper.is_running else "stopped",
            "access_count": memory_keeper.access_count,
            "model_vocab_size": len(model.key_to_index) if model else 0
        })
    return JsonResponse({"status": "not_initialized"})


def stop_memory_keeper(request):
    """ë©”ëª¨ë¦¬ í‚¤í¼ ì¤‘ì§€ (í•„ìš”ì‹œ)"""
    global memory_keeper
    if memory_keeper:
        memory_keeper.stop()
        return JsonResponse({"message": "ë©”ëª¨ë¦¬ í‚¤í¼ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."})
    return JsonResponse({"message": "ë©”ëª¨ë¦¬ í‚¤í¼ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."})


def restart_memory_keeper(request):
    """ë©”ëª¨ë¦¬ í‚¤í¼ ì¬ì‹œì‘"""
    global memory_keeper
    if memory_keeper:
        memory_keeper.stop()
        time.sleep(1)

    if model:
        memory_keeper = PowerfulMemoryKeeper(model)
        memory_keeper.start_background_keeper()
        return JsonResponse({"message": "ë©”ëª¨ë¦¬ í‚¤í¼ê°€ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."})
    return JsonResponse({"message": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."})